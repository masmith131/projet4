{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 1.1 : accessing to data \n",
    "# Needs [ CELL 0 : import ]\n",
    "\n",
    "# defines variables \n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "\n",
    "path_training = 'Retrieving_data\\BelgiumTSC_Training\\Training'\n",
    "path_testing = 'Retrieving_data\\BelgiumTSC_Testing\\Testing'\n",
    "\n",
    "nbr_class = 62 # len(next(walk(path_training))[1])  counting the number of classes \n",
    "print('number of classes : ', nbr_class)\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "\n",
    "# resol is the format for the images that we want for convenience\n",
    "\n",
    "resol = (50,50) # Square image only ! \n",
    "print(\"Resolution of images : \", resol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Retrieving_data.retrieving_data import accessing_2\n",
    "\n",
    "# These are iterators \n",
    "# See fct accessing in codes of Phase 1 \n",
    "training_set = accessing_2(path_training)\n",
    "test_set = accessing_2(path_testing) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Retrieving_data.retrieving_data import store_2\n",
    "\n",
    "# These are arrays\n",
    "# See fct store in codes of Phase 1 \n",
    "X_train, y_train = store_2(training_set, [],[], resol)\n",
    "X_test, y_test = store_2(test_set, [], [], resol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Visualisation.Visu import number\n",
    "from copy import deepcopy\n",
    "\n",
    "initial_nbr_train = number(nbr_class, deepcopy(y_train))\n",
    "initial_nbr_test = number(nbr_class, deepcopy(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Visualisation.Visu import graphs\n",
    "from copy import deepcopy\n",
    "\n",
    "graphs(nbr_class, deepcopy(y_train), deepcopy(y_test), 'y_train', 'y_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import RandomZoom, RandomRotation, RandomCrop, RandomContrast\n",
    "from tensorflow import get_logger\n",
    "from copy import deepcopy\n",
    "from numpy import array\n",
    "\n",
    "# This cell is about data augmentation \n",
    "# We'll randomize our set and do our augmentation with this (cells later)\n",
    "# We choose to work with the second method of augmentation  \n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "\n",
    "get_logger().setLevel('ERROR')\n",
    "\n",
    "data_augmentation = Sequential() \n",
    "\n",
    "data_augmentation.add(RandomZoom(height_factor=(-0.3, -0.2),width_factor=(-0.3, -0.2)))\n",
    "data_augmentation.add(RandomRotation((-0.05, 0.05)))\n",
    "data_augmentation.add(RandomCrop(height=resol[0],width=resol[1]))\n",
    "data_augmentation.add(RandomContrast((1.0,2.0)))\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "\n",
    "# We apply the augmentation on our datasets \n",
    "augmented_image_train = array(data_augmentation(deepcopy(X_train)))\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "\n",
    "print(\"Shape of the randomized training set : \", augmented_image_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import gaussian_filter\n",
    "augmented_image_train = gaussian_filter(augmented_image_train, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint \n",
    "from matplotlib.pyplot import figure, imshow\n",
    "from numpy import zeros \n",
    "\n",
    "# A little test to see the result of the augmentation \n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "\n",
    "index = randint(0,len(X_train))\n",
    "\n",
    "visu_augmented = zeros((50,50,3))\n",
    "\n",
    "for i in range (3) : \n",
    "    for j in range (resol[0]) : \n",
    "        for k in range(resol[1]) : \n",
    "            visu_augmented [j,k,i] = augmented_image_train[index][j,k,i] / 255\n",
    "\n",
    "figure()\n",
    "imshow(X_train[index])\n",
    "figure()\n",
    "imshow(visu_augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from augmentation.aug import first \n",
    "from copy import deepcopy\n",
    "\n",
    "X_train_first, y_train_first = first(nbr_class, deepcopy(initial_nbr_train), deepcopy(initial_nbr_test), deepcopy(augmented_image_train), deepcopy(y_train), resol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Visualisation.Visu import graphs, number\n",
    "\n",
    "nbr_train_first = number(nbr_class, y_train_first)\n",
    "graphs(nbr_class, y_train_first.copy(), y_test.copy(), 'y_train_first', 'y_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from augmentation.aug import second \n",
    "from copy import deepcopy\n",
    "\n",
    "X_train_second, y_train_second = second(nbr_class, deepcopy(initial_nbr_train), deepcopy(augmented_image_train), deepcopy(y_train), resol, max(initial_nbr_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Visualisation.Visu import graphs, number\n",
    "\n",
    "nbr_train_second = number(nbr_class, y_train_second)\n",
    "graphs(nbr_class, y_train_second.copy(), y_test.copy(), 'y_train_second', 'y_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "from copy import deepcopy\n",
    "\n",
    "# We put our results to categorical \n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "\n",
    "y_test_tc = to_categorical(deepcopy(y_test), nbr_class)\n",
    "y_train_tc = to_categorical(deepcopy(y_train), nbr_class)\n",
    "\n",
    "print(\"Shape of y_train without augmentation : \", y_train_tc.shape)\n",
    "print(\"Shape of y_test without augmentation : \", y_test_tc.shape)\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "\n",
    "y_train_first_tc = to_categorical(y_train_first, nbr_class)\n",
    "\n",
    "\n",
    "print(\"Shape of y_train with first method : \", y_train_first_tc.shape)\n",
    "print(\"Shape of y_test with first method : \", y_test_tc.shape)\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "\n",
    "y_train_second_tc = to_categorical(y_train_second, nbr_class)\n",
    "\n",
    "print(\"Shape of y_train with second method : \", y_train_second_tc.shape)\n",
    "print(\"Shape of y_test with second method : \", y_test_tc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout\n",
    "\n",
    "def model_builder(hp):\n",
    "\n",
    "  model = Sequential()\n",
    "\n",
    "  # Tune the number of filters for the second Conv2D \n",
    "  # Choose an optimal value from 64-128\n",
    "\n",
    "  hp_k1 = hp.Int('kernel_1', min_value = 2, max_value = 7, step = 1)\n",
    "  hp_f1 = hp.Int('filter_1', min_value = 64, max_value = 128, step = 4)\n",
    "  model.add(Conv2D(kernel_size=(hp_k1,hp_k1),filters=hp_f1, activation='relu', input_shape=X_train_second.shape[1:]))\n",
    "\n",
    "  hp_k2 = hp.Int('kernel_2', min_value = 2, max_value = 5, step = 1) \n",
    "  model.add(Conv2D(kernel_size=(hp_k2,hp_k2),filters=hp_f1, activation='relu'))\n",
    "\n",
    "  hp_p1 = hp.Int('pool_1', min_value = 2, max_value = 5, step = 1)\n",
    "  model.add(MaxPool2D(pool_size=(hp_p1,hp_p1)))\n",
    "\n",
    "  hp_d1 = hp.Float(\"dropout_1\", min_value=0.1, max_value=0.5, default=0.25, step=0.05)\n",
    "  model.add(Dropout(rate=hp_d1))\n",
    "\n",
    "\n",
    "  hp_k3 = hp.Int('kernel_3', min_value = 2, max_value = 4, step = 1)\n",
    "  hp_f2 = hp.Int('filter_2', min_value = 128, max_value = 256, step = 16)\n",
    "  model.add(Conv2D(kernel_size=(hp_k3,hp_k3),filters=hp_f2, activation='relu'))\n",
    "\n",
    "  hp_k4 = hp.Int('kernel_4', min_value = 2, max_value = 3, step = 1) \n",
    "  model.add(Conv2D(kernel_size=(hp_k4,hp_k4),filters=hp_f2, activation='relu'))\n",
    "\n",
    "  hp_p2 = hp.Int('pool_2', min_value = 2, max_value = 3, step = 1)\n",
    "  model.add(MaxPool2D(pool_size=(hp_p2,hp_p2)))\n",
    "  \n",
    "  hp_d2 = hp.Float(\"dropout_2\", min_value=0.1, max_value=0.5, default=0.25, step=0.05)\n",
    "  model.add(Dropout(rate=hp_d2))\n",
    "  \n",
    "\n",
    "  model.add(Flatten())\n",
    "\n",
    "  hp_units = hp.Int('dense', min_value = 62, max_value = 302, step = 20)\n",
    "  model.add(Dense(hp_units, activation = 'relu'))\n",
    "  model.add(Dense(nbr_class, activation = 'softmax'))\n",
    "\n",
    "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping \n",
    "\n",
    "stop_early = EarlyStopping(baseline=0.98)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective = 'val_accuracy', \n",
    "                     max_epochs = 2,\n",
    "                     factor = 2,\n",
    "                     directory = 'my_dir',\n",
    "                     project_name = 'hyper_tuning',\n",
    "                     overwrite = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search(X_train_second,y_train_second_tc, epochs = 2, verbose = 1, validation_data = (X_test, y_test_tc), callbacks = [stop_early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the optimal hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials = 1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete.\\n \n",
    "The optimal kernel in first Convolutional layer is  {best_hps.get('kernel_1')}.\\n  \n",
    "The optimal filter in first Convolutional layer is  {best_hps.get('filter_1')}.\\n  \n",
    "The optimal kernel in second Convolutional layer is  {best_hps.get('kernel_2')}.\\n\n",
    "The optimal pool for first pooling layer is {best_hps.get('pool_1')}.\\n\n",
    "The optimal rate for first dropout is {best_hps.get('dropout_1')}.\\n\n",
    "The optimal kernel in third Convolutional layer is  {best_hps.get('kernel_3')}.\\n\n",
    "The optimal filter in second Convolutional layer is  {best_hps.get('filter_2')}.\\n\n",
    "The optimal kernel in fourth Convolutional layer is  {best_hps.get('kernel_4')}.\\n\n",
    "The optimal pool for second pooling layer is {best_hps.get('pool_2')}.\\n\n",
    "The optimal rate for second dropout is {best_hps.get('dropout_2')}.\\n\n",
    "The optimal number of units in the first densely-connected layer is {best_hps.get('dense')}.\\n .\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
