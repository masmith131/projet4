{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6  color= 'white' > <b>[LEPL1507] - PROJET P4</b> <br>\n",
    "<br><br>\n",
    "Airson Alexis<br>\n",
    "Beniffou Ibrahim <br>\n",
    "Henneaux Lucas <br>\n",
    "Lemaire Antoine <br>\n",
    "Smith Marielle <br>\n",
    "Canon Th√©o<br>\n",
    "<div style=\"text-align: right\"> </div>\n",
    "\n",
    "<br><br>\n",
    "</font>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the version maintaining the essential parts of code to run\n",
    "\n",
    "Easier to add new features \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6  color= 'white' > <b> Phase 1 : retrieving data </b> <br>\n",
    "\n",
    "The aim of this first part is to get arrays of images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 1.1 : accessing to data \n",
    "# Needs [ CELL 0 : import ]\n",
    "\n",
    "# defines variables \n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "\n",
    "path_training = 'Retrieving_data\\BelgiumTSC_Training\\Training'\n",
    "path_testing = 'Retrieving_data\\BelgiumTSC_Testing\\Testing'\n",
    "\n",
    "nbr_class = 62 # len(next(walk(path_training))[1])  counting the number of classes \n",
    "print('number of classes : ', nbr_class)\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "\n",
    "# resol is the format for the images that we want for convenience\n",
    "\n",
    "resol = (50,50) # Square image only ! \n",
    "print(\"Resolution of images : \", resol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Retrieving_data.retrieving_data import accessing\n",
    "\n",
    "# These are iterators \n",
    "# See fct accessing in codes of Phase 1 \n",
    "training_set = accessing(path_training, resol)\n",
    "test_set = accessing(path_testing, resol) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Retrieving_data.retrieving_data import store\n",
    "\n",
    "# These are arrays\n",
    "# See fct store in codes of Phase 1 \n",
    "X_train, y_train = store(training_set)\n",
    "X_test, y_test = store(test_set)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6  color= 'white' > <b> Phase 2 : visualisation of the dataset </b> <br>\n",
    "\n",
    "The aim of this part is to visualise the initial datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Visualisation.Visu import number\n",
    "from copy import deepcopy\n",
    "\n",
    "initial_nbr_train = number(nbr_class, deepcopy(y_train))\n",
    "initial_nbr_test = number(nbr_class, deepcopy(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Visualisation.Visu import graphs\n",
    "from copy import deepcopy\n",
    "\n",
    "graphs(nbr_class, deepcopy(y_train), deepcopy(y_test), 'y_train', 'y_test')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6  color= 'white' > <b> Phase 3 : randomization of the dataset </b> <br>\n",
    "\n",
    "The aim of this part is to avoid overfitting by applying transformations on the images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import RandomZoom, RandomRotation, RandomCrop, RandomContrast\n",
    "from tensorflow import get_logger\n",
    "from copy import deepcopy\n",
    "from numpy import array\n",
    "\n",
    "# This cell is about data augmentation \n",
    "# We'll randomize our set and do our augmentation with this (cells later)\n",
    "# We choose to work with the second method of augmentation  \n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "\n",
    "get_logger().setLevel('ERROR')\n",
    "\n",
    "data_augmentation = Sequential() \n",
    "\n",
    "data_augmentation.add(RandomZoom(height_factor=(-0.3, -0.2),width_factor=(-0.3, -0.2)))\n",
    "data_augmentation.add(RandomRotation((-0.02, 0.02)))\n",
    "data_augmentation.add(RandomCrop(height=resol[0],width=resol[1]))\n",
    "data_augmentation.add(RandomContrast(0.2))\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "\n",
    "# We apply the augmentation on our datasets \n",
    "augmented_image_train = array(data_augmentation(deepcopy(X_train)))\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "\n",
    "print(\"Shape of the randomized training set : \", augmented_image_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint \n",
    "from matplotlib.pyplot import figure, imshow\n",
    "\n",
    "# A little test to see the result of the augmentation \n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "\n",
    "index = randint(0,len(X_train))\n",
    "figure()\n",
    "imshow(X_train[index])\n",
    "figure()\n",
    "imshow(augmented_image_train[index])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6  color= 'white' > <b> Phase 4 : augmentation of the dataset </b> <br>\n",
    "\n",
    "The aim of this part is to change the sizes of the initial datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from augmentation.aug import first \n",
    "from copy import deepcopy\n",
    "\n",
    "X_train_first, y_train_first = first(nbr_class, deepcopy(initial_nbr_train), deepcopy(initial_nbr_test), deepcopy(augmented_image_train), deepcopy(y_train), resol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Visualisation.Visu import graphs, number\n",
    "\n",
    "nbr_train_first = number(nbr_class, y_train_first)\n",
    "graphs(nbr_class, y_train_first.copy(), y_test.copy(), 'y_train_first', 'y_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from augmentation.aug import second \n",
    "from copy import deepcopy\n",
    "\n",
    "X_train_second, y_train_second = second(nbr_class, deepcopy(initial_nbr_train), deepcopy(augmented_image_train), deepcopy(y_train), resol, max(initial_nbr_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Visualisation.Visu import graphs, number\n",
    "\n",
    "nbr_train_second = number(nbr_class, y_train_second)\n",
    "graphs(nbr_class, y_train_second.copy(), y_test.copy(), 'y_train_second', 'y_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "from copy import deepcopy\n",
    "\n",
    "# We put our results to categorical \n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "\n",
    "y_test_tc = to_categorical(deepcopy(y_test), nbr_class)\n",
    "y_train_tc = to_categorical(deepcopy(y_train), nbr_class)\n",
    "\n",
    "print(\"Shape of y_train without augmentation : \", y_train_tc.shape)\n",
    "print(\"Shape of y_test without augmentation : \", y_test_tc.shape)\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "\n",
    "y_train_first_tc = to_categorical(y_train_first, nbr_class)\n",
    "\n",
    "\n",
    "print(\"Shape of y_train with first method : \", y_train_first_tc.shape)\n",
    "print(\"Shape of y_test with first method : \", y_test_tc.shape)\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "\n",
    "y_train_second_tc = to_categorical(y_train_second, nbr_class)\n",
    "\n",
    "print(\"Shape of y_train with second method : \", y_train_second_tc.shape)\n",
    "print(\"Shape of y_test with second method : \", y_test_tc.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6  color= 'white' > <b> Phase 5 : Construction of the model </b> <br>\n",
    "\n",
    "The aim of this part is to construct a model using CNN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find an optimizer for hyperparameters with the codes of this part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Model.model import construct_model\n",
    "from copy import deepcopy\n",
    "\n",
    "model_simple = construct_model(nbr_class, deepcopy(X_train))\n",
    "\n",
    "model_first = construct_model(nbr_class, deepcopy(X_train_first))\n",
    "\n",
    "model_second = construct_model(nbr_class, deepcopy(X_train_second))\n",
    "\n",
    "model_second.summary() # Same model so same parameters for the 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from copy import deepcopy\n",
    "\n",
    "# We train here the model with the first method of augmentation \n",
    "\n",
    "eps = 3 # The number of time we want the model to train on the entire training_set\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "\n",
    "mycallbacks = [EarlyStopping(monitor='val_loss', patience=5)]\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "\n",
    "validation_X = deepcopy(X_test)\n",
    "validation_y = deepcopy(y_test_tc)\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "\n",
    "anc_second = model_second.fit(X_train_second, y_train_second_tc,validation_data=(validation_X,validation_y), epochs=eps, callbacks=mycallbacks)\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "\n",
    "#added aug.flow to (X_train, y_train) to do data augmentation\n",
    "# validation_data=(X_test_new_first, y_test_new_first)\n",
    "# validation_data=(X_test, y_test)\n",
    "\n",
    "# talk : aug.flow ? \n",
    "# talk : validation data strange "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6  color= 'white' > <b> Phase 6 : Analysis of performances </b> <br>\n",
    "\n",
    "The aim of this part is to analyse the results of the model based on the testing set available "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = open(\"dict.csv\").read().strip().split(\"\\n\")[0:]\n",
    "label_names = [l.split(\",\")[1] for l in label_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Performances.perf import perf \n",
    "\n",
    "perf(anc_second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Performances.perf import ratio_kaggle\n",
    "\n",
    "ratio_kaggle(y_test_tc, X_test, model_second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Performances.perf import network\n",
    "\n",
    "from warnings import filterwarnings\n",
    "\n",
    "filterwarnings('ignore')\n",
    "\n",
    "network(model_second, y_test_tc, X_test, label_names, nbr_class)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6  color= 'white' > <b> Phase 7 : Visualisation of the first kaggle challenge </b> <br>\n",
    "\n",
    "The aim of this part is to visualise the dataset of the first challenge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Visualisation.Visu import to_jpeg\n",
    "\n",
    "folder_dir = \"challenge_1/eval_kaggle1\"\n",
    "to_jpeg(folder_dir)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6  color= 'white' > <b> Phase 8 : Generating csv for kaggle </b> <br>\n",
    "\n",
    "The aim of this part is to predict on the kaggle dataset and generate a csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CSV.CSV import store_2\n",
    "\n",
    "images, names = store_2('challenge_1/eval_kaggle1', resol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import DictReader\n",
    "\n",
    "# We will store the data in dict.csv in a dict \n",
    "\n",
    "data = {}\n",
    "\n",
    "with open('dict.csv', 'r') as f:\n",
    "    d_reader = DictReader(f, fieldnames=[\"num\", \"sign\"])\n",
    "\n",
    "    #get fieldnames from DictReader object and store in list\n",
    "    for row in d_reader:\n",
    "        data[row['num']] = row['sign']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import figure, title, imshow \n",
    "from numpy import uint8\n",
    "\n",
    "# Here's a little test to visualise some results \n",
    "# We then print the image with num and the sign predicted as a title \n",
    "\n",
    "predictions = model_second.predict(images).argmax(axis=1) \n",
    "\n",
    "for i in range(20): \n",
    "    figure(figsize = (10,10))\n",
    "    imshow((images[i] * 255).astype(uint8))\n",
    "    sign = data[str(predictions[i])]\n",
    "    title(str(predictions[i]) + \" : \" + str(sign))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We generate the csv file for kaggle \n",
    "\n",
    "from CSV.CSV import write \n",
    "\n",
    "write(names, predictions, 'kaggle_1')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6  color= 'white' > <b> Part 2 : Cropping </b> <br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6  color= 'white' > <b> Phase 1 : Retrieving images </b> <br>\n",
    "\n",
    "The aim of this part is to retrieve the names of the images to be cropped "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import exists\n",
    "from os import makedirs, system\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "\n",
    "path = \"eval_kaggle2\"\n",
    "dest = \"result_croppped_eval_2\"\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "\n",
    "# Creating required directories \n",
    "\n",
    "if exists(dest):\n",
    "        system('rm -r dest')\n",
    "\n",
    "if not exists(dest):\n",
    "        makedirs(dest)\n",
    "\n",
    "if not exists(path):\n",
    "        makedirs(path)\n",
    "\n",
    "#-----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Retrieving_data.retrieving_data import accessing_2\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "\n",
    "directory = path\n",
    "\n",
    "names = accessing_2(directory)\n",
    "\n",
    "print(\"The number of images to be cropped is : \", len(names))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6  color= 'white' > <b> Phase 2 : Detecting contours </b> <br>\n",
    "\n",
    "The aim of this part is to detect contours on grayscaled images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Contours.contours import detection \n",
    "\n",
    "contours = detection(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A little test to show the result \n",
    "\n",
    "import cv2 \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "for i in range (6) : \n",
    "\n",
    "    im = cv2.imread(names[i])\n",
    "    img = cv2.drawContours(im, contours[i], -1, (0,255,0), 3)\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(img)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6  color= 'white' > <b> Phase 3 : Detecting forms </b> <br>\n",
    "\n",
    "The aim of this part is to detect forms in the contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Contours.contours import classify, forms\n",
    "\n",
    "forms = {} \n",
    "\n",
    "for i in range (len(contours)) : \n",
    "\n",
    "    result = classify(contours[i])\n",
    "\n",
    "    forms[i] = (result[0], result[1], result[2], result[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(max(forms[5][3], key=(forms[5][3]).get))\n",
    "largest = max(forms[5][3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
