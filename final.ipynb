{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6  color= 'white' > <b>[LEPL1507] - PROJET P4</b> <br>\n",
    "<br><br>\n",
    "Airson Alexis<br>\n",
    "Beniffou Ibrahim <br>\n",
    "Henneaux Lucas <br>\n",
    "Lemaire Antoine <br>\n",
    "Smith Marielle <br>\n",
    "Canon Th√©o<br>\n",
    "<div style=\"text-align: right\"> </div>\n",
    "\n",
    "<br><br>\n",
    "</font>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the version maintaining the essential parts of code to run\n",
    "\n",
    "Easier to add new features \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6  color= 'white' > <b> Phase 1 : retrieving data </b> <br>\n",
    "\n",
    "The aim of this first part is to get arrays of images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 1.1 : accessing to data \n",
    "# Needs [ CELL 0 : import ]\n",
    "\n",
    "# defines variables \n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "\n",
    "path_training = 'BelgiumTSC_Training\\Training'\n",
    "path_testing = 'BelgiumTSC_Testing\\Testing'\n",
    "\n",
    "nbr_class = 62 # len(next(walk(path_training))[1])  counting the number of classes \n",
    "print('number of classes : ', nbr_class)\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "\n",
    "# resol is the format for the images that we want for convenience\n",
    "\n",
    "resol = (50,50) # Square image only ! \n",
    "print(\"Resolution of images : \", resol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from retrieving_data import accessing_2\n",
    "\n",
    "# These are iterators \n",
    "# See fct accessing in codes of Phase 1 \n",
    "training_set = accessing_2(path_training)\n",
    "test_set = accessing_2(path_testing) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from retrieving_data import store_2\n",
    "\n",
    "# These are arrays\n",
    "# See fct store in codes of Phase 1 \n",
    "X_train, y_train = store_2(training_set, [],[], resol)\n",
    "X_test, y_test = store_2(test_set, [], [], resol)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6  color= 'white' > <b> Phase 2 : visualisation of the dataset </b> <br>\n",
    "\n",
    "The aim of this part is to visualise the initial datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Visu import number\n",
    "from copy import deepcopy\n",
    "\n",
    "initial_nbr_train = number(nbr_class, deepcopy(y_train))\n",
    "initial_nbr_test = number(nbr_class, deepcopy(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Visu import graphs\n",
    "from copy import deepcopy\n",
    "\n",
    "graphs(nbr_class, deepcopy(y_train), deepcopy(y_test), 'y_train', 'y_test')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6  color= 'white' > <b> Phase 3 : randomization of the dataset </b> <br>\n",
    "\n",
    "The aim of this part is to avoid overfitting by applying transformations on the images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import RandomZoom, RandomRotation, RandomCrop, RandomContrast\n",
    "from tensorflow import get_logger\n",
    "from copy import deepcopy\n",
    "from numpy import array\n",
    "\n",
    "# This cell is about data augmentation \n",
    "# We'll randomize our set and do our augmentation with this (cells later)\n",
    "# We choose to work with the second method of augmentation  \n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "\n",
    "get_logger().setLevel('ERROR')\n",
    "\n",
    "data_augmentation = Sequential() \n",
    "\n",
    "data_augmentation.add(RandomZoom(height_factor=(-0.3, -0.2),width_factor=(-0.3, -0.2)))\n",
    "data_augmentation.add(RandomRotation((-0.05, 0.05)))\n",
    "data_augmentation.add(RandomCrop(height=resol[0],width=resol[1]))\n",
    "data_augmentation.add(RandomContrast((1.0,2.0)))\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "\n",
    "# We apply the augmentation on our datasets \n",
    "augmented_image_train = array(data_augmentation(deepcopy(X_train)))\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "\n",
    "print(\"Shape of the randomized training set : \", augmented_image_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import gaussian_filter\n",
    "augmented_image_train = gaussian_filter(augmented_image_train, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint \n",
    "from matplotlib.pyplot import figure, imshow\n",
    "from numpy import zeros \n",
    "\n",
    "# A little test to see the result of the augmentation \n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "\n",
    "index = randint(0,len(X_train))\n",
    "\n",
    "visu_augmented = zeros((50,50,3))\n",
    "\n",
    "for i in range (3) : \n",
    "    for j in range (resol[0]) : \n",
    "        for k in range(resol[1]) : \n",
    "            visu_augmented [j,k,i] = augmented_image_train[index][j,k,i] / 255\n",
    "\n",
    "figure()\n",
    "imshow(X_train[index])\n",
    "figure()\n",
    "imshow(visu_augmented)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6  color= 'white' > <b> Phase 4 : augmentation of the dataset </b> <br>\n",
    "\n",
    "The aim of this part is to change the sizes of the initial datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aug import first \n",
    "from copy import deepcopy\n",
    "\n",
    "X_train_first, y_train_first = first(nbr_class, deepcopy(initial_nbr_train), deepcopy(initial_nbr_test), deepcopy(augmented_image_train), deepcopy(y_train), resol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Visu import graphs, number\n",
    "\n",
    "nbr_train_first = number(nbr_class, y_train_first)\n",
    "graphs(nbr_class, y_train_first.copy(), y_test.copy(), 'y_train_first', 'y_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aug import second \n",
    "from copy import deepcopy\n",
    "\n",
    "X_train_second, y_train_second = second(nbr_class, deepcopy(initial_nbr_train), deepcopy(augmented_image_train), deepcopy(y_train), resol, max(initial_nbr_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Visu import graphs, number\n",
    "\n",
    "nbr_train_second = number(nbr_class, y_train_second)\n",
    "graphs(nbr_class, y_train_second.copy(), y_test.copy(), 'y_train_second', 'y_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "from copy import deepcopy\n",
    "\n",
    "# We put our results to categorical \n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "\n",
    "y_test_tc = to_categorical(deepcopy(y_test), nbr_class)\n",
    "y_train_tc = to_categorical(deepcopy(y_train), nbr_class)\n",
    "\n",
    "print(\"Shape of y_train without augmentation : \", y_train_tc.shape)\n",
    "print(\"Shape of y_test without augmentation : \", y_test_tc.shape)\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "\n",
    "y_train_first_tc = to_categorical(y_train_first, nbr_class)\n",
    "\n",
    "\n",
    "print(\"Shape of y_train with first method : \", y_train_first_tc.shape)\n",
    "print(\"Shape of y_test with first method : \", y_test_tc.shape)\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "\n",
    "y_train_second_tc = to_categorical(y_train_second, nbr_class)\n",
    "\n",
    "print(\"Shape of y_train with second method : \", y_train_second_tc.shape)\n",
    "print(\"Shape of y_test with second method : \", y_test_tc.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6  color= 'white' > <b> Phase 5 : Construction of the model </b> <br>\n",
    "\n",
    "The aim of this part is to construct a model using CNN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find an optimizer for hyperparameters with the codes of this part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Model.model import construct_model\n",
    "from copy import deepcopy\n",
    "\n",
    "model_simple = construct_model(nbr_class, deepcopy(X_train))\n",
    "\n",
    "model_first = construct_model(nbr_class, deepcopy(X_train_first))\n",
    "\n",
    "model_second = construct_model(nbr_class, deepcopy(X_train_second))\n",
    "\n",
    "model_second.summary() # Same model so same parameters for the 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from copy import deepcopy\n",
    "\n",
    "# We train here the model with the first method of augmentation \n",
    "\n",
    "eps = 3 # The number of time we want the model to train on the entire training_set\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "\n",
    "mycallbacks = [EarlyStopping(monitor='val_loss', patience=5)]\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "\n",
    "validation_X = deepcopy(X_test)\n",
    "validation_y = deepcopy(y_test_tc)\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "\n",
    "anc_second = model_second.fit(X_train_second, y_train_second_tc,validation_data=(validation_X,validation_y), epochs=eps, callbacks=mycallbacks)\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "\n",
    "#added aug.flow to (X_train, y_train) to do data augmentation\n",
    "# validation_data=(X_test_new_first, y_test_new_first)\n",
    "# validation_data=(X_test, y_test)\n",
    "\n",
    "# talk : aug.flow ? \n",
    "# talk : validation data strange "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6  color= 'white' > <b> Phase 6 : Analysis of performances </b> <br>\n",
    "\n",
    "The aim of this part is to analyse the results of the model based on the testing set available "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = open(\"dict.csv\").read().strip().split(\"\\n\")[0:]\n",
    "label_names = [l.split(\",\")[1] for l in label_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from perf import perf \n",
    "\n",
    "perf(anc_second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from perf import ratio_kaggle\n",
    "\n",
    "ratio_kaggle(y_test_tc, X_test, model_second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from perf import network\n",
    "\n",
    "from warnings import filterwarnings\n",
    "\n",
    "filterwarnings('ignore')\n",
    "\n",
    "network(model_second, y_test_tc, X_test, label_names, nbr_class)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6  color= 'white' > <b> Phase 7 : Visualisation of the first kaggle challenge </b> <br>\n",
    "\n",
    "The aim of this part is to visualise the dataset of the first challenge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Visu import to_jpeg\n",
    "\n",
    "folder_dir = \"challenge_1/eval_kaggle1\"\n",
    "to_jpeg(folder_dir)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6  color= 'white' > <b> Phase 8 : Generating csv for kaggle </b> <br>\n",
    "\n",
    "The aim of this part is to predict on the kaggle dataset and generate a csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CSV import store_2\n",
    "\n",
    "images, names = store_2('challenge_1/eval_kaggle1', resol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import DictReader\n",
    "\n",
    "# We will store the data in dict.csv in a dict \n",
    "\n",
    "data = {}\n",
    "\n",
    "with open('dict.csv', 'r') as f:\n",
    "    d_reader = DictReader(f, fieldnames=[\"num\", \"sign\"])\n",
    "\n",
    "    #get fieldnames from DictReader object and store in list\n",
    "    for row in d_reader:\n",
    "        data[row['num']] = row['sign']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import figure, title, imshow \n",
    "from numpy import uint8\n",
    "\n",
    "# Here's a little test to visualise some results \n",
    "# We then print the image with num and the sign predicted as a title \n",
    "\n",
    "predictions = model_second.predict(images).argmax(axis=1) \n",
    "\n",
    "visu_pred = zeros(images.shape)\n",
    "\n",
    "for i in range (images.shape[0]):\n",
    "    for j in range (images.shape[3]) : \n",
    "        for k in range (images.shape[1]):\n",
    "            for l in range (images.shape[2]): \n",
    "                visu_pred[i,k,l,j] = images[i,k,l,j] / 255\n",
    "\n",
    "for i in range(20): \n",
    "    figure(figsize = (10,10))\n",
    "    imshow(visu_pred[i])\n",
    "    sign = data[str(predictions[i])]\n",
    "    title(str(predictions[i]) + \" : \" + str(sign))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We generate the csv file for kaggle \n",
    "\n",
    "from CSV import write \n",
    "\n",
    "write(names, predictions, 'kaggle_1')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6  color= 'white' > <b> Part 2 : Cropping </b> <br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6  color= 'white' > <b> Phase 1 : Detecting forms </b> <br>\n",
    "\n",
    "The aim of this part is to detect forms and contours in the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cv2 import imread, bitwise_and, isContourConvex, boundingRect, minEnclosingCircle, contourArea, imwrite, rectangle, drawContours, waitKey, cvtColor, COLOR_BGR2RGB\n",
    "from os.path import basename, realpath\n",
    "from numpy import pi \n",
    "\n",
    "from contours import edges, cont, HSV, parameters\n",
    "\n",
    "def process_shape(raw_image, dest, f) : \n",
    "\n",
    "    process_image = raw_image.copy() #copy the image\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    edge_detected_image = edges(process_image)\n",
    "\n",
    "    contours = cont(edge_detected_image)\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    process_image = raw_image.copy()\n",
    "\n",
    "    mask = HSV(process_image)\n",
    "\n",
    "    # Apply mask to image to remove grayscale regions\n",
    "    masked_image = bitwise_and(process_image, process_image, mask=mask)\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    edge_detected_image = edges(masked_image)\n",
    "\n",
    "    contours = cont(edge_detected_image)\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    shapes = [] \n",
    "    for contour in contours:\n",
    "\n",
    "        length, approx, area, perimeter, circularity = parameters(contour)\n",
    "\n",
    "        #----------------------------------------------------------------------------------------------------------\n",
    "        # A lot of conditions to classify forms \n",
    "        \n",
    "        if circularity < 0.8:\n",
    "            continue\n",
    "\n",
    "        if not isContourConvex(approx):\n",
    "            continue\n",
    "\n",
    "        if len(approx) == 3: # We're looking for triangles \n",
    "            shapes.append(contour)\n",
    "\n",
    "        elif len(approx) == 4: # We're looking for squares and losanges \n",
    "            (x, y, w, h) = boundingRect(approx)\n",
    "            ar = w / float(h)\n",
    "            if (ar >= 0.8 and ar <= 1.2):\n",
    "                shapes.append(contour)\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        elif len(approx) == 8: # We're looking for octogones\n",
    "            shapes.append(contour)\n",
    "\n",
    "        elif len(approx) > 8: # check if contour has a circular shape\n",
    "            (x, y), radius = minEnclosingCircle(contour)\n",
    "            area = contourArea(contour)\n",
    "            if radius > 0 and area / (pi * radius**2) >= 0.8:\n",
    "                shapes.append(contour)\n",
    "\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    #----------------------------------------------------------------------------------------------------------\n",
    "    # Find contours with largest areas for each shape\n",
    "\n",
    "    try:\n",
    "        best_contour = max(shapes, key=lambda x: contourArea(x))\n",
    "    except ValueError:\n",
    "        best_contour = None\n",
    "\n",
    "    if best_contour is None:\n",
    "        print(' No shape found')\n",
    "        #bounding box is the whole image\n",
    "        imwrite(dest + \"/\" + basename(realpath(f)).replace('.ppm', '.jpeg'), raw_image)\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    #----------------------------------------------------------------------------------------------------------\n",
    "    # If it worked, crop the image with a rectangle around the detected shape \n",
    "    \n",
    "    (x,y,w,h) = boundingRect(best_contour)\n",
    "    rectangle(raw_image, (x,y), (x+w,y+h), (0,255,0), 2)\n",
    "    drawContours(raw_image, [best_contour],  -1, (255,0,0), 2)\n",
    "    waitKey()\n",
    "\n",
    "    raw_image = raw_image[y:y + h, x:x + w]\n",
    "    img = imread(f)\n",
    "    img = cvtColor(img,COLOR_BGR2RGB)   \n",
    "\n",
    "    imwrite(dest + \"/\"+ basename(realpath(f)).replace('.ppm', '.jpeg'), raw_image)\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cv2 import imread, GaussianBlur, imshow, waitKey, medianBlur, drawContours, COLOR_BGR2HSV, inRange, bitwise_or, findContours, RETR_EXTERNAL, CHAIN_APPROX_SIMPLE, arcLength, contourArea, convexHull\n",
    "from numpy import array, pi \n",
    "from os.path import basename, realpath\n",
    "\n",
    "from retrieving_data import accessing_2\n",
    "\n",
    "def process(path, dest):\n",
    "\n",
    "    #----------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    names = accessing_2(path)\n",
    "\n",
    "    #----------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    for f in names : \n",
    "\n",
    "        raw_image = imread(f) #load the image\n",
    "        process_image = raw_image.copy() #copy the image\n",
    "        if(process_shape(raw_image, dest, f)):\n",
    "            continue\n",
    "\n",
    "        # On floute avec du gaussian puis du median blur\n",
    "        blur = GaussianBlur(process_image, (9, 9), 0)\n",
    "        blur = medianBlur(blur, 9)\n",
    "\n",
    "        # On transforme l'image en image HSV\n",
    "        img_hsv = cvtColor(blur, COLOR_BGR2HSV)\n",
    "        img_hsv[...,1] = img_hsv[...,1]*1.4\n",
    "\n",
    "\n",
    "        # D√©finit la range du rouge en HSV\n",
    "        lower_red = array([0, 50, 50])\n",
    "        upper_red = array([10, 255, 255])\n",
    "\n",
    "        # Cr√©e un masque pour la couleur rouge en utilisant la range d√©finie\n",
    "        mask1 = inRange(img_hsv, lower_red, upper_red)\n",
    "        # Masque rouge valeurs hautes\n",
    "        lower_red = array([170, 70, 50])\n",
    "        upper_red = array([180, 255, 255])\n",
    "        mask_red = inRange(img_hsv.copy(), lower_red, upper_red)\n",
    "\n",
    "        mask_red = bitwise_or(mask1, mask_red)\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------------\n",
    "\n",
    "        # Masque bleu\n",
    "        lower_blue = array([90, 100, 100])\n",
    "        upper_blue = array([121, 255, 255])\n",
    "        mask_blue = inRange(img_hsv.copy(), lower_blue, upper_blue)\n",
    "\n",
    "        #Total mask\n",
    "        mask_red_blue = bitwise_or(mask_red, mask_blue)\n",
    "\n",
    "        #show image with mask\n",
    "        # imshow('mask', mask_red_blue)\n",
    "        # waitKey()\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------------\n",
    "\n",
    "        # Trouve les contours dans l'image filtr√©e\n",
    "        contours, _ = findContours(mask_red_blue, RETR_EXTERNAL, CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        #draw image with contours\n",
    "        drawContours(process_image, contours, -1, (0, 255, 0), 3)\n",
    "        # imshow('contour', process_image)\n",
    "        # waitKey()\n",
    "\n",
    "        # Initialise une liste vide pour stocker les contours valides\n",
    "        list_contour = []\n",
    "        best_contour = None\n",
    "\n",
    "        # Parcourt tous les contours trouv√©s\n",
    "        for cnt in contours:\n",
    "\n",
    "            # Calcule le rectangle englobant le contour\n",
    "            x, y, w, h = boundingRect(cnt)\n",
    "            #imposer que le bounding box soit plus grand que 5% de l'image \n",
    "            \n",
    "            if (w*h) < (0.0005*raw_image.shape[0]*raw_image.shape[1]):\n",
    "                print(\"condition 1\")\n",
    "                continue\n",
    "\n",
    "            #imposer que le bounding box soit pas un rectangle tr√®s plat \n",
    "            if (w/h) < 0.7 or (w/h) > 1.3:\n",
    "                print(\"condition 2\")\n",
    "                continue\n",
    "\n",
    "            #if it is a circle very likely to be a round road sign\n",
    "            area = contourArea(cnt)\n",
    "            perimeter = arcLength(cnt, True)\n",
    "            circularity = 4 * pi * area / perimeter ** 2\n",
    "            if circularity > 0.8:\n",
    "                best_contour = cnt\n",
    "                list_contour.append(cnt)\n",
    "                break\n",
    "            \n",
    "            #convexit√© ? \n",
    "            hull = convexHull(cnt)\n",
    "            hull_area = contourArea(hull)\n",
    "            solidity = float(area)/hull_area\n",
    "            if solidity < 0.7:\n",
    "                print(\"condition 3\")\n",
    "                continue\n",
    "            \n",
    "            list_contour.append(cnt)\n",
    "\n",
    "        print(len(list_contour))\n",
    "\n",
    "        after_contour = raw_image.copy()\n",
    "        drawContours(after_contour, list_contour, -1, (0, 255, 0), 3)\n",
    "        # imshow('after contour', after_contour)\n",
    "        # waitKey()\n",
    "\n",
    "        #----------------------------------------------------------------------------------------------------------\n",
    "\n",
    "        if(len(list_contour) == 0):\n",
    "            print(\"No contour found\")\n",
    "            continue\n",
    "            \n",
    "        if(best_contour is None):\n",
    "            #get max of list_contour\n",
    "            best_contour = max(list_contour, key=lambda x: contourArea(x))\n",
    "\n",
    "        #----------------------------------------------------------------------------------------------------------\n",
    "\n",
    "        (x,y,w,h) = boundingRect(best_contour)\n",
    "        rectangle(raw_image, (x,y), (x+w,y+h), (0,255,0), 2)\n",
    "        drawContours(raw_image, [best_contour],  -1, (255,0,0), 2)\n",
    "        waitKey()\n",
    "        raw_image = raw_image[y:y + h, x:x + w]\n",
    "        img = imread(f)\n",
    "        img = cvtColor(img, COLOR_BGR2RGB)   \n",
    "        imwrite(dest+\"/\"+basename(realpath(f)).replace('.ppm', '.jpeg'), raw_image)\n",
    "\n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import exists\n",
    "from os import system, makedirs\n",
    "\n",
    "# from Visu import show_images\n",
    "\n",
    "path = \"eval_kaggle2\"\n",
    "dest = \"result_croppped_eval_2\"\n",
    "\n",
    "if exists(dest):\n",
    "    system('rm -r dest')\n",
    "\n",
    "if not exists(dest):\n",
    "    makedirs(dest)\n",
    "\n",
    "if not exists(path):\n",
    "    makedirs(path)\n",
    "\n",
    "names = process(path, dest)\n",
    "#show_images(dest)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6  color= 'white' > <b> Phase 2 : Generating a CSV for kaggle </b> <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CSV import store_2\n",
    "\n",
    "images, names = store_2('result_croppped_eval_2', resol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import DictReader\n",
    "\n",
    "# We will store the data in dict.csv in a dict \n",
    "\n",
    "data = {}\n",
    "\n",
    "with open('dict.csv', 'r') as f:\n",
    "    d_reader = DictReader(f, fieldnames=[\"num\", \"sign\"])\n",
    "\n",
    "    #get fieldnames from DictReader object and store in list\n",
    "    for row in d_reader:\n",
    "        data[row['num']] = row['sign']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import figure, title, imshow \n",
    "from numpy import uint8\n",
    "\n",
    "# Here's a little test to visualise some results \n",
    "# We then print the image with num and the sign predicted as a title \n",
    "\n",
    "predictions = model_second.predict(images).argmax(axis=1) \n",
    "\n",
    "visu_pred = zeros(images.shape)\n",
    "\n",
    "for i in range (images.shape[0]):\n",
    "    for j in range (images.shape[3]) : \n",
    "        for k in range (images.shape[1]):\n",
    "            for l in range (images.shape[2]): \n",
    "                visu_pred[i,k,l,j] = images[i,k,l,j] / 255\n",
    "\n",
    "for i in range(20): \n",
    "    figure(figsize = (10,10))\n",
    "    imshow(visu_pred[i])\n",
    "    sign = data[str(predictions[i])]\n",
    "    title(str(predictions[i]) + \" : \" + str(sign))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We generate the csv file for kaggle \n",
    "\n",
    "from CSV import write \n",
    "\n",
    "write(names, predictions, 'kaggle_2')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
